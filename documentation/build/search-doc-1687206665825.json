[{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt; Click me!","keywords":""},{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":""},{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":""},{"title":"Backup kubernetes namespace with Kasten10 by Veeam","type":0,"sectionRef":"#","url":"/docs/Backup/Backup kubernetes namespace with Kasten10 by Veeam","content":"","keywords":""},{"title":"Prerequisites​","type":1,"pageTitle":"Backup kubernetes namespace with Kasten10 by Veeam","url":"/docs/Backup/Backup kubernetes namespace with Kasten10 by Veeam#prerequisites","content":"Before proceeding with the backup policy configuration, ensure the following prerequisites are met: Deployed Kasten10 by Veeam to GKE cluster (previous Documentation)Access to GCP.IAM service account with appropriate privileges for accessing and managing backups. "},{"title":"Step 1: Adding Storage for Namespace Backups​","type":1,"pageTitle":"Backup kubernetes namespace with Kasten10 by Veeam","url":"/docs/Backup/Backup kubernetes namespace with Kasten10 by Veeam#step-1-adding-storage-for-namespace-backups","content":"Folow the steps in the video tutorial below that demonstrates how to add the storage location for namespace backups:  "},{"title":"Step 2: Adding Backup Policies for Each Namespace​","type":1,"pageTitle":"Backup kubernetes namespace with Kasten10 by Veeam","url":"/docs/Backup/Backup kubernetes namespace with Kasten10 by Veeam#step-2-adding-backup-policies-for-each-namespace","content":"Folow the steps in the video tutorial below that explains how to add backup policies for each namespace:  Additional Considerations Here are some additional considerations to keep in mind while configuring backup policies with GCP Veeam service: Regularly review and update backup policies to accommodate changing requirements.Perform periodic tests and validations to ensure the backup and restore processes are functioning properly.Monitor backup operations and review logs for any potential errors or warnings.Adhere to backup retention policies that align with your organization's data retention and regulatory requirements. "},{"title":"Veeam Use Cases","type":0,"sectionRef":"#","url":"/docs/Backup/Introduction","content":"Veeam Use Cases Veeam is a comprehensive backup and disaster recovery solution that offers various use cases to meet the needs of different organizations. Here are some common use cases where Veeam proves to be valuable: Data Backup and Recovery: Veeam enables organizations to protect their critical data by implementing regular backup strategies. It provides efficient and reliable backup mechanisms for virtual, physical, and cloud-based environments. With Veeam, you can easily restore data to its original state or recover specific files and folders, ensuring business continuity and minimizing downtime. Disaster Recovery: Veeam offers robust disaster recovery capabilities to minimize the impact of potential disasters such as hardware failures, natural disasters, or cyber-attacks. It provides replication and failover mechanisms that allow you to quickly recover your entire IT infrastructure or specific workloads in a secondary location, ensuring high availability and business resiliency. Cloud Data Management: Veeam simplifies the management of data in multi-cloud and hybrid cloud environments. It allows you to seamlessly migrate workloads between on-premises and public cloud platforms, perform cloud-native backups, and leverage cloud storage for cost-effective long-term data retention. Veeam's cloud data management capabilities help organizations optimize their cloud usage, ensure data protection, and achieve greater flexibility and scalability. Virtual Infrastructure Monitoring: Veeam provides comprehensive monitoring and reporting features for virtualized environments. It allows you to gain deep insights into the performance, capacity, and health of your virtual infrastructure, making it easier to identify bottlenecks, optimize resource allocation, and proactively resolve issues. Veeam's monitoring capabilities help ensure the smooth operation of your virtualized environment and enhance overall performance. Data Governance and Compliance: Veeam helps organizations meet data governance and compliance requirements by offering features such as data classification, retention policies, and data immutability. It allows you to classify sensitive data, apply appropriate retention rules, and ensure data integrity through immutability settings, enabling compliance with regulations like GDPR, HIPAA, or PCI-DSS. These are just a few examples of the versatile use cases that Veeam supports. By leveraging Veeam's powerful backup, recovery, and data management capabilities, organizations can enhance their data protection strategies, streamline operations, and ensure the availability and integrity of their critical data.","keywords":""},{"title":"Installatation of Kasten10 by Veaam","type":0,"sectionRef":"#","url":"/docs/Backup/Installatation of Kasten10 by Veaam","content":"","keywords":""},{"title":"Step 1: Create a K10 Service Account​","type":1,"pageTitle":"Installatation of Kasten10 by Veaam","url":"/docs/Backup/Installatation of Kasten10 by Veaam#step-1-create-a-k10-service-account","content":""},{"title":"Create a K10 service account​","type":1,"pageTitle":"Installatation of Kasten10 by Veaam","url":"/docs/Backup/Installatation of Kasten10 by Veaam#create-a-k10-service-account","content":"myproject=$(gcloud config get-value core/project)  gcloud iam service-accounts create k10-sa --display-name &quot;K10 Service Account&quot;  k10saemail=$(gcloud iam service-accounts list --filter &quot;k10-sa&quot; --format=&quot;value(email)&quot;)  "},{"title":"Generate a key file (k10-sa-key.json)​","type":1,"pageTitle":"Installatation of Kasten10 by Veaam","url":"/docs/Backup/Installatation of Kasten10 by Veaam#generate-a-key-file-k10-sa-keyjson","content":"gcloud iam service-accounts keys create --iam-account=${k10saemail} k10-sa-key.json  "},{"title":"Assign the necessary permissions to the service account for storage administration.​","type":1,"pageTitle":"Installatation of Kasten10 by Veaam","url":"/docs/Backup/Installatation of Kasten10 by Veaam#assign-the-necessary-permissions-to-the-service-account-for-storage-administration","content":"gcloud projects add-iam-policy-binding ${myproject} --member serviceAccount:${k10saemail} --role roles/compute.storageAdmin  "},{"title":"Step 2: Add Kasten Helm Repository and Create Namespace​","type":1,"pageTitle":"Installatation of Kasten10 by Veaam","url":"/docs/Backup/Installatation of Kasten10 by Veaam#step-2-add-kasten-helm-repository-and-create-namespace","content":"Add the Kasten Helm repository to your local repository list by running the following commands: helm repo add kasten https://charts.kasten.io/  Create a namespace named kasten-io where K10 will be installed by running the following commands: kubectl create namespace kasten-io  "},{"title":"Step 3: Install Kasten K10 using Helm​","type":1,"pageTitle":"Installatation of Kasten10 by Veaam","url":"/docs/Backup/Installatation of Kasten10 by Veaam#step-3-install-kasten-k10-using-helm","content":"Exports the contents of the k10-sa-key.json file as a base64-encoded value and assigns it to the sa_key environment variable, which can be used for authentication or configuration purposes in subsequent commands, use the following command: export sa_key=$(base64 k10-sa-key.json) # export sa_key=$(base64 -w0 k10-sa-key.json)  Install K10 in the kasten-io namespace and sets the Google API key using the contents of the base64-encoded k10-sa-key.json file by typing the following command: helm install k10 kasten/k10 --namespace=kasten-io --set secrets.googleApiKey=$sa_key  "},{"title":"Step 4: Access Veeam Dashboard using Port Forward​","type":1,"pageTitle":"Installatation of Kasten10 by Veaam","url":"/docs/Backup/Installatation of Kasten10 by Veaam#step-4-access-veeam-dashboard-using-port-forward","content":"To access the Veeam dashboard, execute the following command: kubectl --namespace kasten-io port-forward service/gateway 8080:8000  After running this command, open your web browser and visit http://127.0.0.1:8080/k10/#/ to access the Veeam dashboard. For a more detailed guide, please refer to the blog post at the following link "},{"title":"Documentation: Configuring Backup Policies with GCP Veeam Service","type":0,"sectionRef":"#","url":"/docs/Backup/Backup Developer workstation with Veeam","content":"","keywords":""},{"title":"Overview​","type":1,"pageTitle":"Documentation: Configuring Backup Policies with GCP Veeam Service","url":"/docs/Backup/Backup Developer workstation with Veeam#overview","content":"This documentation provides a step-by-step guide on how to configure backup policies using the GCP Veeam service. By following these instructions, you can ensure effective backup management for your developer instances in Google Cloud Platform (GCP). This documentation also references a video tutorial that demonstrates the configuration process. "},{"title":"Prerequisites​","type":1,"pageTitle":"Documentation: Configuring Backup Policies with GCP Veeam Service","url":"/docs/Backup/Backup Developer workstation with Veeam#prerequisites","content":"Before proceeding with the backup policy configuration, ensure the following prerequisites are met: Access to GCP Veeam service.IAM service account with appropriate privileges for accessing and managing backups.Familiarity with the GCP console and Veeam backup concepts. "},{"title":"Step-by-Step Guide​","type":1,"pageTitle":"Documentation: Configuring Backup Policies with GCP Veeam Service","url":"/docs/Backup/Backup Developer workstation with Veeam#step-by-step-guide","content":""},{"title":"Step 1: Creating a Veeam Server​","type":1,"pageTitle":"Documentation: Configuring Backup Policies with GCP Veeam Service","url":"/docs/Backup/Backup Developer workstation with Veeam#step-1-creating-a-veeam-server","content":"Access the GCP console and navigate to the Veeam service page. Click on &quot;Create Veeam Server&quot; and provide the necessary details, such as server name and configuration settings. Review and confirm the server creation. Access Veeam Create a veeam account and sign in to the dashboard "},{"title":"Step 2: Updating IAM Service Account Privileges​","type":1,"pageTitle":"Documentation: Configuring Backup Policies with GCP Veeam Service","url":"/docs/Backup/Backup Developer workstation with Veeam#step-2-updating-iam-service-account-privileges","content":"Identify the IAM service account associated with the Veeam server.Access the IAM &amp; Admin section in the GCP console.Locate the IAM service account and click on it.Update the account privileges to include the necessary roles or permissions required for backup operations. "},{"title":"Step 3: Configuring Backup Policy​","type":1,"pageTitle":"Documentation: Configuring Backup Policies with GCP Veeam Service","url":"/docs/Backup/Backup Developer workstation with Veeam#step-3-configuring-backup-policy","content":"Open the GCP Veeam service console and select the desired Veeam server.Navigate to the backup policies section and click on &quot;Create Backup Policy.&quot;Configure the backup policy settings, including retention periods, scheduling, and backup targets.Save the backup policy settings. "},{"title":"Step 4: Assigning Backup Policy to Developer Instances​","type":1,"pageTitle":"Documentation: Configuring Backup Policies with GCP Veeam Service","url":"/docs/Backup/Backup Developer workstation with Veeam#step-4-assigning-backup-policy-to-developer-instances","content":"Access the GCP Compute Engine console.Identify the developer instances that require backup.Assign the previously created backup policy to the respective instances. Additional Considerations Regularly review and update backup policies to align with changing requirements.Perform periodic tests and validate the backup and restore processes to ensure data recoverability.Monitor backup operations and review logs for any errors or warnings.Consider implementing backup retention policies that comply with your organization's data retention and regulatory requirements. "},{"title":"Configuration Management","type":0,"sectionRef":"#","url":"/docs/Configuration Management/Introduction","content":"","keywords":""},{"title":"Introduction​","type":1,"pageTitle":"Configuration Management","url":"/docs/Configuration Management/Introduction#introduction","content":"This section provides an overview of configuration management using AWX, serverspec, and Ansible dynamic inventory. Configuration management is essential for maintaining consistent and reliable system configurations across your infrastructure. By following these guidelines, you can streamline your configuration management processes and ensure efficient management of your servers and applications. "},{"title":"Importance of Configuration Management​","type":1,"pageTitle":"Configuration Management","url":"/docs/Configuration Management/Introduction#importance-of-configuration-management","content":"Configuration management offers several key benefits: Consistency: Ensuring that all systems and servers are configured consistently helps maintain stability and reduces the risk of configuration drift.Reproducibility: Configuration management allows you to reproduce configurations across multiple environments, making it easier to deploy and manage applications.Efficiency: Automating configuration tasks saves time and effort, enabling faster and more reliable deployments.Auditing and Compliance: Configuration management facilitates tracking and auditing of configuration changes, ensuring compliance with industry standards and regulatory requirements.Scalability: As your infrastructure grows, configuration management helps you efficiently manage and scale your systems. "},{"title":"Installing and Configuring AWX​","type":1,"pageTitle":"Configuration Management","url":"/docs/Configuration Management/Introduction#installing-and-configuring-awx","content":"AWX is an open-source web-based user interface for Ansible. It provides a centralized platform for managing Ansible playbooks, inventories, and job scheduling. This section covers the installation and configuration process for AWX. "},{"title":"Using Ansible Dynamic Inventory​","type":1,"pageTitle":"Configuration Management","url":"/docs/Configuration Management/Introduction#using-ansible-dynamic-inventory","content":"Ansible dynamic inventory allows you to dynamically generate inventory data from external sources. It automates the management of your inventory without manual updates. This section explains the usage of Ansible dynamic inventory. "},{"title":"Installing and Configuring serverspec​","type":1,"pageTitle":"Configuration Management","url":"/docs/Configuration Management/Introduction#installing-and-configuring-serverspec","content":"serverspec is a Ruby-based tool for writing automated tests for infrastructure. It helps ensure that your servers are properly configured and meet the desired state. This section covers the installation and configuration process for serverspec. Note Please refer to the respective sections for detailed instructions and demonstrations. "},{"title":"AWX Trigger Pipeline","type":0,"sectionRef":"#","url":"/docs/Continous Integration/Jenkins Pipelines/AWX Pipeline","content":"","keywords":""},{"title":"Configuring AWX","type":0,"sectionRef":"#","url":"/docs/Configuration Management/Configuring AWX","content":"","keywords":""},{"title":"Requirements​","type":1,"pageTitle":"Configuring AWX","url":"/docs/Configuration Management/Configuring AWX#requirements","content":"Important Service account file Public key must be imported to developers's GCP instances "},{"title":"Steps to Configure AWX​","type":1,"pageTitle":"Configuring AWX","url":"/docs/Configuration Management/Configuring AWX#steps-to-configure-awx","content":"Create Organization: In AWX, an organization represents a logical grouping of related projects, credentials, and inventories. To create an organization, follow these steps: Access the AWX interface and navigate to the &quot;Organizations&quot; section.Click on &quot;Add&quot; to create a new organization.Provide the necessary details, such as the organization name and description.Save the organization configuration. Create Credentials: Credentials in AWX are used to store information necessary to access various systems and services. Follow these steps to create credentials: Go to the &quot;Credentials&quot; section in AWX.Click on &quot;Add&quot; to create a new set of credentials.Select the appropriate credential type (SSH and GCP) and provide the required details.Save the credentials. Dynamic Inventory: AWX supports dynamic inventories, which can automatically discover and manage hosts. To set up a dynamic inventory, perform the following steps: Navigate to the &quot;Inventories&quot; section in AWX.Click on &quot;Add&quot; to create a new inventory.Choose the inventory type as &quot;Dynamic&quot; and configure the necessary settings (e.g., source, credential, etc.).Save the dynamic inventory configuration. Create Project: Projects in AWX are used to manage source code repositories and define playbooks. To create a project, follow these steps: Access the &quot;Projects&quot; section in AWX.Click on &quot;Add&quot; to create a new project.Provide the project name, select the appropriate SCM type (e.g., Git, Mercurial), and provide the repository URL.Save the project configuration. Create Template: Templates in AWX define the jobs to be executed. To create a template, follow these steps: Go to the &quot;Templates&quot; section in AWX.Click on &quot;Add&quot; to create a new template.Provide the template name, select the project and playbook, and configure any required variables and options.Save the template configuration. Test Job Template: After creating the job template, you can test it to ensure it runs successfully. Follow these steps: Access the &quot;Templates&quot; section in AWX.Find the desired job template and click on the rocket icon to launch the job.Monitor the job status and output to verify its success. Step-by-Step Video Explanation: Here's a video tutorial that provides a detailed walkthrough of the AWX configuration process.  By following these steps, you can configure AWX and set up organizations, credentials, dynamic inventories, projects, templates, and execute job templates successfully. "},{"title":"Prerequisites​","type":1,"pageTitle":"AWX Trigger Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/AWX Pipeline#prerequisites","content":"Before running the AWX Trigger pipeline, ensure the following prerequisites are met: Jenkins: Set up Jenkins on your system or cluster.Ansible Tower: Install and configure Ansible Tower, also known as AWX, and set up the necessary job templates.Jenkins Credentials: Create a Jenkins credential of type &quot;Username with password&quot; to store the AWX credentials. This credential should be referenced as awxcredentials in the pipeline. "},{"title":"Pipeline Configuration​","type":1,"pageTitle":"AWX Trigger Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/AWX Pipeline#pipeline-configuration","content":"pipeline { agent any stages { stage('Trigger Docker Ansible Tower Job') { steps { ansibleTower jobTemplate: 'docker', jobType: 'run', scmBranch: 'main', throwExceptionWhenFail: false, towerCredentialsId: 'awxcredentials ', towerLogLevel: 'full', towerServer: 'awx' } } stage('Trigger Dev Tools Ansible Tower Job') { steps { ansibleTower jobTemplate: 'devtools', jobType: 'run', scmBranch: 'main', throwExceptionWhenFail: false, towerCredentialsId: 'awxcredentials ', towerLogLevel: 'full', towerServer: 'awx' } } } }  "},{"title":"Stages and Steps​","type":1,"pageTitle":"AWX Trigger Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/AWX Pipeline#stages-and-steps","content":"The AWX Trigger pipeline consists of the following stages: Trigger Docker Ansible Tower Job: This stage triggers the Docker job template in AWX.Trigger Dev Tools Ansible Tower Job: This stage triggers the Dev Tools job template in AWX. Each stage uses the ansibleTower step to trigger the corresponding job template in AWX. stage('Trigger Docker Ansible Tower Job') { steps { ansibleTower jobTemplate: 'docker', jobType: 'run', scmBranch: 'main', throwExceptionWhenFail: false, towerCredentialsId: 'awxcredentials', towerLogLevel: 'full', towerServer: 'awx' } }  In this example, the ansibleTower step is used to trigger the docker job template. Adjust the jobTemplate parameter to match the name of your Docker job template in AWX. You can also customize other parameters according to your specific requirements. stage('Trigger Dev Tools Ansible Tower Job') { steps { ansibleTower jobTemplate: 'devtools', jobType: 'run', scmBranch: 'main', throwExceptionWhenFail: false, towerCredentialsId: 'awxcredentials', towerLogLevel: 'full', towerServer: 'awx' } }  In this example, the ansibleTower step is used to trigger the devtools job template. Adjust the jobTemplate parameter to match the name of your Dev Tools job template in AWX. Customize other parameters as needed. Make sure to replace awxcredentials with the actual Jenkins credential ID for your AWX credentials. Remember to adjust the towerServer value to match the AWX server you are using. Please note that this is a simplified overview of the pipeline, and you may need to modify it according to your specific requirements and environment. "},{"title":"Infrastructure Creation Pipeline","type":0,"sectionRef":"#","url":"/docs/Continous Integration/Jenkins Pipelines/Infrastructure Pipeline","content":"","keywords":""},{"title":"Overview​","type":1,"pageTitle":"Infrastructure Creation Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Infrastructure Pipeline#overview","content":"The Infrastructure Creation pipeline is responsible for creating the Developer Instances along side the GKE Cluster using Terraform. This pipeline automates the process of provisioning infrastructure resources on Google Cloud Platform (GCP). "},{"title":"Prerequisites​","type":1,"pageTitle":"Infrastructure Creation Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Infrastructure Pipeline#prerequisites","content":"Before running the Infrastructure Creation pipeline, make sure you have the following prerequisites: Jenkins: Set up Jenkins on your system or cluster.Google Cloud SDK: Install and configure the Google Cloud SDK on the Jenkins agent or the system running the pipeline.Jenkins Credentials: Create a Jenkins credential of type &quot;File&quot; to store the service account key JSON file. This credential should be referenced as serviceaccount in the pipeline. "},{"title":"Plugins to Install​","type":1,"pageTitle":"Infrastructure Creation Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Infrastructure Pipeline#plugins-to-install","content":"To execute this pipeline, ensure that the following Jenkins plugins are installed: PipelineCredentials BindingGoogle OAuth CredentialsGoogle Cloud SDKTerraform "},{"title":"Pipeline Configuration​","type":1,"pageTitle":"Infrastructure Creation Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Infrastructure Pipeline#pipeline-configuration","content":"The infrastructure pipeline is defined using the Jenkins Declarative Pipeline syntax. Here is an example of the pipeline configuration: pipeline { agent any tools { terraform 'terraform' } environment { SERVICE_ACCOUNT_KEY = credentials('serviceaccount') } stages { stage('Clone') { steps { echo 'Cloning the repo' git branch: 'main', url: 'https://github.com/Chamssiddine/remote-development-environment.git' } } stage('Authenticate with Google Cloud') { steps { withCredentials([file(credentialsId: 'serviceaccount', variable: 'SERVICE_ACCOUNT_KEY')]) { sh &quot;&quot;&quot; gcloud auth activate-service-account --key-file=${SERVICE_ACCOUNT_KEY} gcloud config set account \\$(gcloud auth list --filter=status:ACTIVE --format='value(account)') gcloud config set project remotedevenv-383413 &quot;&quot;&quot; } } } stage('Initialize Infrastructure') { steps { dir('infrastructure') { withEnv([&quot;GOOGLE_APPLICATION_CREDENTIALS=${SERVICE_ACCOUNT_KEY}&quot;]) { sh ''' terraform init ''' } } } } stage('Plan Infrastructure Changes') { steps { dir('infrastructure') { withEnv([&quot;GOOGLE_APPLICATION_CREDENTIALS=${SERVICE_ACCOUNT_KEY}&quot;]) { sh ''' terraform plan ''' } } } } stage('Apply Infrastructure Changes') { steps { dir('infrastructure') { withEnv([&quot;GOOGLE_APPLICATION_CREDENTIALS=${SERVICE_ACCOUNT_KEY}&quot;]) { sh ''' terraform apply -auto-approve ''' } } } } } }  "},{"title":"Stages and Steps​","type":1,"pageTitle":"Infrastructure Creation Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Infrastructure Pipeline#stages-and-steps","content":"The Infrastructure Creation pipeline consists of the following stages: Clone: This stage clones the repository containing the Terraform configuration files.Authenticate with Google Cloud: This stage authenticates with Google Cloud using the provided service account key file.Initialize Infrastructure: This stage initializes Terraform within the infrastructure directory.Plan Infrastructure Changes: This stage generates the execution plan for Terraform to determine the changes required to provision the infrastructure.Apply Infrastructure Changes: This stage applies the changes defined in the Terraform configuration to provision the infrastructure resources on Google Cloud Platform. Each stage contains steps that execute specific commands or actions required for that stage. Please note that this is a simplified overview of the pipeline, and you may need to modify it according to your specific requirements and environment. Make sure to have the necessary credentials, plugins, and configurations in place before running the pipeline. "},{"title":"Installing AWX","type":0,"sectionRef":"#","url":"/docs/Configuration Management/Installing AWX","content":"","keywords":""},{"title":"How to install AWX using kubernetes operator​","type":1,"pageTitle":"Installing AWX","url":"/docs/Configuration Management/Installing AWX#how-to-install-awx-using-kubernetes-operator","content":"To install AWX using Kubernetes Operator, follow these steps: "},{"title":"1. Navigate to the awx-operator directory:​","type":1,"pageTitle":"Installing AWX","url":"/docs/Configuration Management/Installing AWX#1-navigate-to-the-awx-operator-directory","content":"cd helm_charts/awx_chart  "},{"title":"2. Verify the content of the following files:​","type":1,"pageTitle":"Installing AWX","url":"/docs/Configuration Management/Installing AWX#2-verify-the-content-of-the-following-files","content":"tip You can specify the version of AWX operator in kustomization.yaml You can modify the specs of AWX to your needs in awx.yml. "},{"title":"3. Run the kustomize command to build the Kubernetes manifest and apply it:​","type":1,"pageTitle":"Installing AWX","url":"/docs/Configuration Management/Installing AWX#3-run-the-kustomize-command-to-build-the-kubernetes-manifest-and-apply-it","content":"kubectl apply -k . # kustomize build . | kubectl apply -f -  "},{"title":"3. To get the initial passowrd type in​","type":1,"pageTitle":"Installing AWX","url":"/docs/Configuration Management/Installing AWX#3-to-get-the-initial-passowrd-type-in","content":"kubectl get secret awx-admin-password -n awx -o jsonpath=&quot;{.data.password}&quot; | base64 --decode ; echo  IMPORTANT: It may take some time to create the pods for AWX. It will create the AWX controller manager first. If it takes longer than expected, retype the same command until you see the 4 replicas of AWX. To check if the pods are created or not, type in the following command: kubectl get pods -n awx -w  "},{"title":"Access AWX","type":0,"sectionRef":"#","url":"/docs/Developer Access/Access AWX","content":"Access AWX","keywords":""},{"title":"Overview","type":0,"sectionRef":"#","url":"/docs/Continous Integration/Overview","content":"","keywords":""},{"title":"Continuous Integration with Jenkins​","type":1,"pageTitle":"Overview","url":"/docs/Continous Integration/Overview#continuous-integration-with-jenkins","content":"In our platform, we have chosen Jenkins as the continuous integration tool due to its flexibility and vast range of plugins. Jenkins will play a crucial role in automating the deployment process and managing the state of the infrastructure. "},{"title":"GitOps Principles​","type":1,"pageTitle":"Overview","url":"/docs/Continous Integration/Overview#gitops-principles","content":"We strongly adhere to the GitOps principles in our workflow. All our infrastructure-as-code (IaC) code is stored in GitHub repositories. When changes are pushed to the repositories, Jenkins is triggered to create or modify the state of the infrastructure accordingly. This ensures a streamlined and efficient development process, where infrastructure changes are version-controlled and automatically applied. Throughout this documentation, you will find step-by-step instructions, best practices, and tips for utilizing Jenkins and following the GitOps principles to maximize the effectiveness and productivity of your remote development environment. Let's get started! "},{"title":"Access GCP instance","type":0,"sectionRef":"#","url":"/docs/Developer Access/Access GCP instance","content":"","keywords":""},{"title":"Step 1 install ssh plugin in VSCODE​","type":1,"pageTitle":"Access GCP instance","url":"/docs/Developer Access/Access GCP instance#step-1-install-ssh-plugin-in-vscode","content":""},{"title":"Step 2 Configure Access to the GCP instance​","type":1,"pageTitle":"Access GCP instance","url":"/docs/Developer Access/Access GCP instance#step-2-configure-access-to-the-gcp-instance","content":""},{"title":"Step 3 Add GCP instance to Hosts​","type":1,"pageTitle":"Access GCP instance","url":"/docs/Developer Access/Access GCP instance#step-3-add-gcp-instance-to-hosts","content":""},{"title":"Step 4 Access GCP instance​","type":1,"pageTitle":"Access GCP instance","url":"/docs/Developer Access/Access GCP instance#step-4-access-gcp-instance","content":""},{"title":"CommingSoon","type":0,"sectionRef":"#","url":"/docs/Disaster Recovery/CommingSoon","content":"CommingSoon Scaling and managing the infrastructure Customizing and extending the environment Detail the steps involved in recovering from a disaster using Veeam backup.Document the necessary preparations and configurations required for a successful recovery.Provide guidelines for restoring the development environment from the Veeam backup.","keywords":""},{"title":"Serverspec","type":0,"sectionRef":"#","url":"/docs/Configuration Management/Serverspec","content":"","keywords":""},{"title":"Why Use ServerSpec with Ansible​","type":1,"pageTitle":"Serverspec","url":"/docs/Configuration Management/Serverspec#why-use-serverspec-with-ansible","content":"While Ansible is a powerful infrastructure automation tool that can provision, configure, and orchestrate servers, it does not provide built-in testing capabilities. ServerSpec, on the other hand, is a testing framework specifically designed to verify the state and configuration of servers. Here are a few reasons why using ServerSpec with Ansible can be beneficial: Validation of Desired State: Ansible ensures that servers are provisioned and configured according to the desired state defined in your Ansible playbooks. However, it's essential to validate that the applied configurations are accurate and meet the expected outcomes. ServerSpec enables you to write tests in a human-readable format to verify the state of the provisioned servers, ensuring that they adhere to the desired configuration. Continuous Integration and Deployment: ServerSpec tests can be integrated into your continuous integration and deployment pipelines. By including ServerSpec tests alongside your Ansible playbooks, you can perform automated testing to validate the correctness of your infrastructure and catch any configuration issues or unexpected changes before deploying to production. Documentation and Compliance: ServerSpec tests serve as documentation for your infrastructure. They provide clear and concise statements about the expected configuration and behavior of your servers. Additionally, ServerSpec can help you meet compliance requirements by ensuring that your servers adhere to specific security or regulatory standards. By combining the automation capabilities of Ansible with the testing capabilities of ServerSpec, you can have more confidence in the correctness and stability of your infrastructure. "},{"title":"Docker ServerSpec File: docker_spec.rb​","type":1,"pageTitle":"Serverspec","url":"/docs/Configuration Management/Serverspec#docker-serverspec-file-docker_specrb","content":"require 'serverspec' set :backend, :exec describe package('docker-ce') do it { should be_installed } end describe package('docker-ce-cli') do it { should be_installed } end describe package('containerd.io') do it { should be_installed } end describe service('docker') do it { should be_enabled } it { should be_running } end  The docker_spec.rb file is a ServerSpec test file that verifies the state of Docker on a server. It contains a series of tests using the ServerSpec syntax to check if Docker packages are installed and if the Docker service is enabled and running. The tests in the docker_spec.rb file perform the following verifications: Check if the docker-ce package is installed.Check if the docker-ce-cli package is installed.Check if the containerd.io package is installed.Check if the Docker service is enabled and running. By running these ServerSpec tests, you can ensure that Docker is correctly installed and functioning on the target servers. "},{"title":"Dev Tools ServerSpec File: dev_tools.rb​","type":1,"pageTitle":"Serverspec","url":"/docs/Configuration Management/Serverspec#dev-tools-serverspec-file-dev_toolsrb","content":"require 'serverspec' # Define the packages to be installed packages = %w[curl wget rsync golang-go ansible vagrant ruby git] set :backend, :exec # Check if the packages are installed packages.each do |package| describe package(package) do it { should be_installed } end end  The dev_tools.rb file is a ServerSpec test file that verifies if the dev tools are installed on the dev workstations or not. It contains a series of tests using the ServerSpec syntax to check if the packages installed by AWX(ansible) are installed. The tests in the docker_spec.rb file perform the following verifications: Check if curl wget rsync golang-go ansible vagrant ruby git package are installed. "},{"title":"Bash Script: serverspec.bash​","type":1,"pageTitle":"Serverspec","url":"/docs/Configuration Management/Serverspec#bash-script-serverspecbash","content":"#!/bin/bash # Generate the list of instances with zone europe-west9-a instances=$(gcloud compute instances list --filter=&quot;zone:(europe-west9-a)&quot; --format=&quot;value(name)&quot;) # Path to the docker_spec.rb file spec_file=&quot;docker_spec.rb&quot; dev_tools=&quot;dev_tools.rb&quot; # Copy docker_spec.rb to each instance and run the tests for instance in $instances; do echo &quot;Copying docker_spec.rb and dev_tools to $instance...&quot; gcloud compute scp $spec_file $instance:~/ --zone=europe-west9-a gcloud compute scp $dev_tools $instance:~/ --zone=europe-west9-a echo &quot;Installing Serverspec on $instance...&quot; # SSH into the instance and install Serverspec gcloud compute ssh $instance --zone=europe-west9-a --command=&quot;sudo gem install serverspec &gt;/dev/null &amp;&amp; sudo gem install serverspec | tail -n 2&quot; echo &quot;Running tests on $instance...&quot; # SSH into the instance and run the tests, suppressing the warning message gcloud compute ssh $instance --zone=europe-west9-a --command=&quot;sudo rspec ~/docker_spec.rb --format documentation&quot; gcloud compute ssh $instance --zone=europe-west9-a --command=&quot;sudo rspec ~/dev_tools.rb --format documentation&quot; echo &quot;Cleaning up docker_spec.rb and dev_tools on $instance...&quot; # Remove the copied docker_spec.rb file from the instance gcloud compute ssh $instance --zone=europe-west9-a --command=&quot;rm ~/docker_spec.rb ~/dev_tools.rb&quot; done  "},{"title":"Run the serverspec tests​","type":1,"pageTitle":"Serverspec","url":"/docs/Configuration Management/Serverspec#run-the-serverspec-tests","content":"Navigate to the serverspec folder by typing the following command: cd provision/serverspec/spec  the script will copy the serverspec files to each of the instance in europe-west9-a zone, install serverspec with gem and run the serverspec files To run the run_docker_serverspec.bash script, run the following command: bash serverspec.bash  The script will execute the ServerSpec tests on each instance and display the output, including the status of the tests and any error messages. "},{"title":"How to start with the project","type":0,"sectionRef":"#","url":"/docs/Getting Started/Requirements","content":"","keywords":""},{"title":"Step 1: Clone the Git Repository​","type":1,"pageTitle":"How to start with the project","url":"/docs/Getting Started/Requirements#step-1-clone-the-git-repository","content":"To get started, you'll need to clone the project repository. You can do this by running the following command in your terminal: $ git clone https://github.com/Chamssiddine/remote-development-environment  This will create a local copy of the project on your computer. "},{"title":"Step 2: Requirements​","type":1,"pageTitle":"How to start with the project","url":"/docs/Getting Started/Requirements#step-2-requirements","content":"Our project has a few requirements that you'll need to meet in order to get it up and running: Terraform : is an open-source infrastructure as code software tool, You can download Terraform from the official website at https://developer.hashicorp.com/terraform/downloads. GCP : Our project uses Google Cloud Platform (GCP) as its cloud provider. You'll need to have a GCP account set up and create a new project before you can get started. If you don't have a GCP account, you can sign up for a free trial at https://cloud.google.com. Ansible : is an open-source automation tool that allows you to automate the deployment and configuration of software and infrastructure. You can download Ansible from the official website at https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html. Docker Python "},{"title":"Step 3: Installation​","type":1,"pageTitle":"How to start with the project","url":"/docs/Getting Started/Requirements#step-3-installation","content":"Once you have met the requirements outlined in Step 2, you can begin the installation process. Here are the steps you'll need to follow: Install Terraform, Ansible, Docker, Python and GCP: Follow the instructions provided on the official website on your computer. "},{"title":"Introduction","type":0,"sectionRef":"#","url":"/docs/Infrastructure as a Code/Introduction","content":"","keywords":""},{"title":"Infrastructure as Code and Terraform​","type":1,"pageTitle":"Introduction","url":"/docs/Infrastructure as a Code/Introduction#infrastructure-as-code-and-terraform","content":"We embrace the concept of Infrastructure as Code (IaC) to manage our infrastructure effectively. Terraform, an industry-leading IaC tool, allows us to define and provision our infrastructure using declarative configurations. With Terraform, we can codify our desired infrastructure state, including the creation and configuration of our GKE cluster, IAM roles and bindings for developers. This approach ensures consistency, reproducibility, and scalability of our infrastructure, reducing the risk of configuration drift and enabling efficient collaboration across teams. "},{"title":"Installation of Jenkins","type":0,"sectionRef":"#","url":"/docs/Continous Integration/Installation of Jenkins","content":"","keywords":""},{"title":"Step 1: Prepare the Jenkins Environment​","type":1,"pageTitle":"Installation of Jenkins","url":"/docs/Continous Integration/Installation of Jenkins#step-1-prepare-the-jenkins-environment","content":"Ensure that you have a dedicated machine or a local environment to deploy Jenkins.Create a separate directory for your continuous integration setup. . ├── README.md ├── docker-compose.yaml ├── infrastructurePipeline │ └── Jenkinsfile └── installgcloud.bash  Navigate to the continuous integration folder. cd ContinousIntegration  "},{"title":"Step 2: Launch Jenkins Docker Container​","type":1,"pageTitle":"Installation of Jenkins","url":"/docs/Continous Integration/Installation of Jenkins#step-2-launch-jenkins-docker-container","content":"Create a docker-compose.yaml file with the following content to configure and launch the Jenkins Docker container: version: '3' services: jenkins: image: jenkins/jenkins:2.401.1-lts-jdk11 container_name: jenkins user: root ports: - 8080:8080 - 50000:50000 volumes: - jenkins_home:/var/jenkins_home restart: always volumes: jenkins_home:  Start the Jenkins container by running the following command: docker-compose up -d  "},{"title":"Step 3: Install Required Plugins​","type":1,"pageTitle":"Installation of Jenkins","url":"/docs/Continous Integration/Installation of Jenkins#step-3-install-required-plugins","content":"Access the Jenkins web interface by opening a browser and visiting http://localhost:8080.Install the following plugins through the Jenkins Plugin Manager: PipelineTerraformDockerKubernetes (Kube)Google Cloud CLI (gcloud) "},{"title":"Step 4: Configure Jenkins Credentials​","type":1,"pageTitle":"Installation of Jenkins","url":"/docs/Continous Integration/Installation of Jenkins#step-4-configure-jenkins-credentials","content":"Add your service account credentials as a secret file in Jenkins. This will allow Jenkins to access the necessary resources for deployment.Follow the Jenkins documentation to add the credentials as a secret file. "},{"title":"Step 5: Create and Configure the Pipeline​","type":1,"pageTitle":"Installation of Jenkins","url":"/docs/Continous Integration/Installation of Jenkins#step-5-create-and-configure-the-pipeline","content":"Create a new pipeline in Jenkins.Copy the contents of the Jenkinsfile located in the infrastructurePipeline folder and paste it into the pipeline configuration. "},{"title":"Step 6: Configure Triggers​","type":1,"pageTitle":"Installation of Jenkins","url":"/docs/Continous Integration/Installation of Jenkins#step-6-configure-triggers","content":"Configure the triggers for your pipeline according to your requirements. For example, you can trigger the pipeline on code commits or on a schedule. "},{"title":"Step 7: Build the Pipeline​","type":1,"pageTitle":"Installation of Jenkins","url":"/docs/Continous Integration/Installation of Jenkins#step-7-build-the-pipeline","content":"Save your pipeline configuration and build the pipeline. Jenkins will now execute the defined steps in the pipeline, deploying your infrastructure as specified in the Jenkinsfile. NOTE This is a general overview of the installation and configuration process. Further customization and adjustments may be required based on your specific requirements. "},{"title":"Google kubernetes Engine Cluster","type":0,"sectionRef":"#","url":"/docs/Infrastructure as a Code/Terraform Modules/Google kubernetes Engine Cluster","content":"","keywords":""},{"title":"Module Purpose​","type":1,"pageTitle":"Google kubernetes Engine Cluster","url":"/docs/Infrastructure as a Code/Terraform Modules/Google kubernetes Engine Cluster#module-purpose","content":"GKE Cluster Module "},{"title":"Deploying the Kubernetes Cluster​","type":1,"pageTitle":"Google kubernetes Engine Cluster","url":"/docs/Infrastructure as a Code/Terraform Modules/Google kubernetes Engine Cluster#deploying-the-kubernetes-cluster","content":"To deploy our Kubernetes cluster, you'll need to navigate to the kubernetes Terraform module by running the following command: $ cd infrastructure/modules/kubernetes  Next, you'll need to apply the Terraform file using the following command: $ terraform apply  This will deploy the necessary infrastructure on your cloud provider (e.g. Google Cloud Platform) and provision the Kubernetes cluster. "},{"title":"Customizing the Kubernetes Cluster​","type":1,"pageTitle":"Google kubernetes Engine Cluster","url":"/docs/Infrastructure as a Code/Terraform Modules/Google kubernetes Engine Cluster#customizing-the-kubernetes-cluster","content":"If you'd like to customize the Kubernetes cluster, you can modify the default variables in the variable.tf file. This file contains all the configurable variables for the Terraform module. Once you've made the necessary changes, you can re-run the terraform apply command to apply the changes to the Kubernetes cluster. "},{"title":"Exploring the Kubernetes Cluster​","type":1,"pageTitle":"Google kubernetes Engine Cluster","url":"/docs/Infrastructure as a Code/Terraform Modules/Google kubernetes Engine Cluster#exploring-the-kubernetes-cluster","content":"Congratulations, you've successfully deployed the Kubernetes cluster! Now, you can explore the features of the cluster using tools like kubectl. There are many other commands you can use to explore and manage the Kubernetes cluster. We recommend checking out the official Kubernetes documentation for more information. That's it for this guide. "},{"title":"Root Module","type":0,"sectionRef":"#","url":"/docs/Infrastructure as a Code/Terraform Modules/Root Module","content":"","keywords":""},{"title":"Usage​","type":1,"pageTitle":"Root Module","url":"/docs/Infrastructure as a Code/Terraform Modules/Root Module#usage","content":"If you're not using Jenkins to create the infrastructure, follow these steps: Navigate to the infrastructure directory in your terminal.Run the following commands: terraform init # This installs the necessary Terraform dependencies. terraform plan # This shows the changes that will be made in the infrastructure. terraform apply -auto-approve # This applies the changes to the infrastructure automatically without asking for confirmation.  "},{"title":"Terraform Configuration​","type":1,"pageTitle":"Root Module","url":"/docs/Infrastructure as a Code/Terraform Modules/Root Module#terraform-configuration","content":"Here's the Terraform code for the root module: module &quot;workstation&quot; { source = &quot;./modules/workstation&quot; gcp_project = var.gcp_project gcp_region = var.gcp_region gcp_zone = var.gcp_zone storage_class = var.storage_class } output &quot;allworkstationip&quot; { value = module.workstation.ip } module &quot;kubernetes&quot; { source = &quot;./modules/kubernetes&quot; gcp_project = var.gcp_project } output &quot;k8sclustersname&quot; { value = module.kubernetes.k8sclustername }  "},{"title":"Dependencies​","type":1,"pageTitle":"Root Module","url":"/docs/Infrastructure as a Code/Terraform Modules/Root Module#dependencies","content":"This module has the following dependencies: Google Cloud Terraform Provider: Version 3.0 or later.Google Cloud SDK: The GCP SDK must be installed and authenticated. Make sure to install and configure these dependencies before using this module. NOTE Feel free to modify and customize the content based on your specific module and requirements. "},{"title":"Running Ansible Playbook with Dynamic Inventory","type":0,"sectionRef":"#","url":"/docs/Configuration Management/Ansible","content":"","keywords":""},{"title":"Transferring SSH Public Key to Workstations Using Bash Scripts​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#transferring-ssh-public-key-to-workstations-using-bash-scripts","content":"To transfer an SSH public key to workstations, follow these steps: $ cd scripts  this is the folders we need: . ├── ansible_playbook │ ├── README.md │ ├── gcp.yml │ ├── docker_playbook.yml │ ├── packages_playbook.yml │ └── start_ansible_playbook.bash └── ssh ├── README.md ├── put_here_your_ssh_key_to_send.bash ├── remove_knowhost.bash └── ssh_to_workstation.bash  Remove any old known host to prevent conflicts by running the following command:  $ rm ~/.ssh/know_hosts  Transfer SSH Public Key to Workstations IMPORTANT: Choose the method that suits you: a. GCP Metadata b. Send machine's public key to GCP instances Prepare the file to send to GCP instance by creating a new directory using the following command:  $ mkdir ~/.ssh/auth_keys  Add the public key to the authorized_keys file using the following command:  $ echo ~/.ssh/&lt;publickey.pub&gt; &gt; ~/.ssh/auth_keys/authorized_keys  Run the following script to transfer the public key to all workstations:  $ bash send_publickey_to_workstation.bash  "},{"title":"Running the ansible Playbook using Dynamic Inventory​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#running-the-ansible-playbook-using-dynamic-inventory","content":"General Steps Create a service account. Get the credentials JSON file. Create the dynamic inventory file. Run your playbook. "},{"title":"1. Create service account​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#1-create-service-account","content":"To create a service account, run the following command:  $ gcloud iam service-accounts create ansibledyinv --display-name &quot;ansibledyinv&quot;  "},{"title":"List the service accounts to see the service account email created​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#list-the-service-accounts-to-see-the-service-account-email-created","content":" $ gcloud iam service-accounts list  "},{"title":"Add the role to your service account email​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#add-the-role-to-your-service-account-email","content":" $ gcloud projects add-iam-policy-binding &lt;PROJECT_ID&gt; --member &quot;serviceAccount:&lt;SERVICE_ACCOUNT_EMAIL&gt;&quot; --role &quot;roles/compute.instanceAdmin.v1&quot;  "},{"title":"2. Export the service account key json file​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#2-export-the-service-account-key-json-file","content":"$ gcloud iam service-accounts keys create /opt/ansible/inventory/service-account.json --iam-account &lt;SERVICE_ACCOUNT_EMAIL&gt;   "},{"title":"3. Create the dynamic inventory file​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#3-create-the-dynamic-inventory-file","content":"To create the dynamic inventory file, navigate to the ansible_playbook directory and create a new file called gcp.yml with the following contents: plugin: gcp_compute zones: # populate inventory with instances in these regions - europe-west9-a projects: - &lt;PROJECT_ID&gt; auth_kind: serviceaccount service_account_file: /opt/ansible/inventory/service-account.json groups: workstation_instances:  You can modify it according to your preferences, in short we will target the vm in a specific zone.  "},{"title":"4. Run your playbook​","type":1,"pageTitle":"Running Ansible Playbook with Dynamic Inventory","url":"/docs/Configuration Management/Ansible#4-run-your-playbook","content":"Choose the playbook you want to run. For example:  A. Installing Docker. B. Installing multiple tools for our Developers.  Run the playbook using the following command: $ ansible-playbook --user=&lt;gcp account name&gt; --private-key=~/.ssh/publickey.pub -i gcp.yml ThePlayBook.yml  Replace &lt;gcp_account_name&gt; with your GCP account name, and ThePlayBook.yml with the name of the playbook you want to run (e.g., docker_playbook.yml or packages_playbook.yml).  IMPORTANTMake sure to replace  I. &lt;PROJECT_ID&gt; with your actual GCP project ID II. &lt;SERVICE_ACCOUNT_EMAIL&gt; with the service account email you obtained III. &lt;publickey.pub&gt; with the actual filename of your SSH public key.  By following these steps, you should be able to transfer the SSH public key to workstations and run your Ansible playbook using dynamic inventory on GCP instances. "},{"title":"Introduction","type":0,"sectionRef":"#","url":"/docs/intro","content":"","keywords":""},{"title":"Project Purpose​","type":1,"pageTitle":"Introduction","url":"/docs/intro#project-purpose","content":"I created a remote development environment project to tackle all the challenges posed by the increasing complexity of software and the need to recruit new developers. As I noticed, setting up a development environment manually can be a time-consuming process, particularly for new developers who are not familiar with the system. Therefore, my project aims to leverage cloud-based technologies such as GCP, Ansible, Terraform, AWX, CI/CD, Kubernetes, and SSO with Keycloak to streamline the setup process and allow developers to start creating software efficiently. With my project, developers can access a secure and flexible platform that can be accessed from anywhere, using any device, and eliminate the constraints of hardware or software requirements.  "},{"title":"Configuration of Grafana Dashboards","type":0,"sectionRef":"#","url":"/docs/Monitoring/Configuration of Grafana Dashboards","content":"","keywords":""},{"title":"Configuration of Grafana Dashboards​","type":1,"pageTitle":"Configuration of Grafana Dashboards","url":"/docs/Monitoring/Configuration of Grafana Dashboards#configuration-of-grafana-dashboards","content":""},{"title":"Enabling VPC Peering​","type":1,"pageTitle":"Configuration of Grafana Dashboards","url":"/docs/Monitoring/Configuration of Grafana Dashboards#enabling-vpc-peering","content":"In this project, we have two VPCs: one for the developer workstation and one for the GKE cluster. To establish communication between the VPCs, we need to enable VPC peering for both. For a detailed walkthrough, watch the following video:  "},{"title":"Configuring Grafana Dashboard with Prometheus​","type":1,"pageTitle":"Configuration of Grafana Dashboards","url":"/docs/Monitoring/Configuration of Grafana Dashboards#configuring-grafana-dashboard-with-prometheus","content":"Next, we will add Prometheus server as a data source and create a Grafana dashboard. For a step-by-step demonstration, watch the following video:  "},{"title":"Add Developer roles and Access","type":0,"sectionRef":"#","url":"/docs/Infrastructure as a Code/Terraform Modules/Add Developer roles and Access","content":"Add Developer roles and Access To add a new developer and role binding, as well as a new role, navigate to infrastructure/modules/IamRbac follow these steps: Add a new developer: Open the Terraform configuration file rolebinding.tf.Locate the developers local block.Add a new entry within the developers block, specifying the details of the new developer, such as their email address, namespace, and desired role.Uncomment and customize the role_rules if you want to specify custom rules for the developer's role.Save the file. locals { developers = { roleone = { email = &quot;chamseddine.abderrahim@gmail.com&quot; namespace = &quot;chamseddine&quot; role_name = &quot;developer-role&quot; }, roletwo = { email = &quot;mahdi.bouzidi@gmail.com&quot; namespace = &quot;mahdi&quot; role_name = &quot;viewer-role&quot; }, newdeveloper = { email = &quot;newdeveloper@gmail.com&quot; namespace = &quot;newnamespace&quot; role_name = &quot;newrole&quot; }, # Add more developers as needed } } Add a new role: Open the Terraform configuration file role.tf.Locate the roles local block.Add a new entry within the roles block, specifying the details of the new role, such as its name, API groups, resources, and verbs.Save the file. locals { roles = { developer1 = { name = &quot;developer-role&quot; api_groups = [&quot;&quot;] resources = [&quot;pods&quot;, &quot;services&quot;, &quot;deployments&quot;, &quot;configmaps&quot;, &quot;secrets&quot;, &quot;persistentvolumeclaims&quot;, &quot;ingresses&quot;, &quot;jobs&quot;, &quot;cronjobs&quot;, &quot;replicasets&quot;, &quot;statefulsets&quot;, &quot;daemonsets&quot;] verbs = [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;] }, developer2 = { name = &quot;viewer-role&quot; api_groups = [&quot;&quot;] resources = [&quot;pods&quot;, &quot;services&quot;] verbs = [&quot;get&quot;, &quot;list&quot;, &quot;watch&quot;, &quot;create&quot;, &quot;update&quot;, &quot;patch&quot;, &quot;delete&quot;] }, newrole = { name = &quot;new-role&quot; api_groups = [&quot;&quot;] resources = [&quot;deployments&quot;, &quot;configmaps&quot;] verbs = [&quot;get&quot;, &quot;list&quot;, &quot;create&quot;] }, # Add more roles as needed } } Update the IAM bindings: Open the Terraform configuration file iam.tf.Locate the iam_bindings local block.Add a new entry within the iam_bindings block, associating the email address of the new developer with their desired role.Save the file. locals { iam_bindings = { &quot;chamseddine.abderrahim@gmail.com&quot; = &quot;roles/container.developer&quot; &quot;mahdi.bouzidi@gmail.com&quot; = &quot;roles/container.developer&quot; &quot;newdeveloper@gmail.com&quot; = &quot;roles/container.viewer&quot; # Assigning the new developer to an existing role } } Run terraform plan and terraform apply in the ROOT Module to apply the changes and create the new developer, role binding, and role. IMPORTANT Ensure that you have the necessary permissions and credentials to make changes to the IAM bindings and roles. NOTE Please adapt the code examples to match your existing naming conventions and specific requirements.","keywords":""},{"title":"Serverspec Testing Pipeline","type":0,"sectionRef":"#","url":"/docs/Continous Integration/Jenkins Pipelines/Serverspec Pipeline","content":"","keywords":""},{"title":"Prerequisites​","type":1,"pageTitle":"Serverspec Testing Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Serverspec Pipeline#prerequisites","content":"Before running the Serverspec Testing pipeline, ensure the following prerequisites are met: Jenkins: Set up Jenkins on your system or cluster.Google Cloud SDK: Install and configure the Google Cloud SDK on the Jenkins agent or the system running the pipeline.Jenkins Credentials: Create a Jenkins credential of type &quot;File&quot; to store the service account key JSON file. This credential should be referenced as serviceaccount in the pipeline. "},{"title":"Pipeline Configuration​","type":1,"pageTitle":"Serverspec Testing Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Serverspec Pipeline#pipeline-configuration","content":"def getInstances() { def instances = sh( script: &quot;gcloud compute instances list --filter=\\&quot;zone:(europe-west9-a)\\&quot; --format=\\&quot;value(name)\\&quot;&quot;, returnStdout: true ).trim().split(&quot;\\n&quot;) return instances } pipeline { agent any environment { SERVICE_ACCOUNT_KEY = credentials('serviceaccount') } stages { stage('Clone Repository') { steps { echo 'Cloning the repository' git branch: 'main', url: 'https://github.com/Chamssiddine/remote-development-environment.git' } } stage('Authenticate with Google Cloud') { steps { withCredentials([file(credentialsId: 'serviceaccount', variable: 'SERVICE_ACCOUNT_KEY')]) { sh ''' gcloud auth activate-service-account --key-file=${SERVICE_ACCOUNT_KEY} gcloud config set account $(gcloud auth list --filter=status:ACTIVE --format='value(account)') gcloud config set project remotedevenv-383413 ''' } } } stage('Install Serverspec On Developers Instances') { steps { echo 'Installing Serverspec on all instances...' script { def instances = getInstances() parallel instances.collectEntries { instance -&gt; return [ &quot;${instance}&quot; : { sh &quot;gcloud compute ssh ${instance} --zone=europe-west9-a --command=\\&quot;sudo gem install serverspec &gt;/dev/null &amp;&amp; sudo gem install serverspec | tail -n 2\\&quot;&quot; } ] } } } } stage('Docker Serverspec Tests') { steps { echo 'Copying docker_spec.rb to all instances...' script { def instances = getInstances() def specFile = &quot;provision/server_spec/spec/docker_spec.rb&quot; parallel instances.collectEntries { instance -&gt; return [ &quot;${instance}&quot; : { sh &quot;gcloud compute scp ${specFile} ${instance}:~/ --zone=europe-west9-a&quot; sh &quot;gcloud compute ssh ${instance} --zone=europe-west9-a --command=\\&quot;sudo rspec ~/docker_spec.rb --format documentation\\&quot;&quot; } ] } } } } stage('Run Dev Tools Serverspec Tests') { steps { echo 'Copying dev_tools.rb and running additional tests on all instances...' script { def instances = getInstances() def devTools = &quot;provision/server_spec/spec/dev_tools.rb&quot; parallel instances.collectEntries { instance -&gt; return [ &quot;${instance}&quot; : { sh &quot;gcloud compute scp ${devTools} ${instance}:~/ --zone=europe-west9-a&quot; sh &quot;gcloud compute ssh ${instance} --zone=europe-west9-a --command=\\&quot;sudo rspec ~/dev_tools.rb --format documentation\\&quot;&quot; } ] } } } } } }  "},{"title":"Stages and Steps​","type":1,"pageTitle":"Serverspec Testing Pipeline","url":"/docs/Continous Integration/Jenkins Pipelines/Serverspec Pipeline#stages-and-steps","content":"The Serverspec Testing pipeline consists of the following stages: Clone Repository: This stage clones the repository containing the Serverspec test files.Authenticate with Google Cloud: This stage authenticates with Google Cloud using the provided service account key file.Install Serverspec On Developers Instances: This stage installs Serverspec on all instances used by developers in parallel.Docker Serverspec Tests: This stage copies the docker_spec.rb file to each instance and runs the Serverspec tests for Docker.Run Dev Tools Serverspec Tests: This stage copies the dev_tools.rb file to each instance and runs additional Serverspec tests for dev tools. Each stage contains steps that execute specific commands or actions required for that stage. You can further customize these steps according to your specific Serverspec tests and requirements. Please note that the getInstances() function is not defined in the provided code snippet. You need to implement this function to retrieve the instance names based on your criteria, such as zone or any other relevant filter. Remember to adjust the zone (europe-west9-a) and project ID (remotedevenv-383413) values according to your specific project details. Make sure to have the necessary credentials, plugins, and configurations in place before running the pipeline. Please note that this is a simplified overview of the pipeline, and you may need to modify it according to your specific requirements and environment. "},{"title":"Installation of Prometheus","type":0,"sectionRef":"#","url":"/docs/Monitoring/Installation of Prometheus","content":"Installation of Prometheus Navigate to the Prometheus chart directory: cd helm_charts/prometheus_chart Add the Prometheus Helm chart repository from prometheus-community: helm repo add prometheus-community https://prometheus-community.github.io/helm-charts Install Prometheus using the Helm chart. We provided the chart values customized for our needs, but you can make your changes as you wish. Specify the custom values file with -f flag: helm install prometheus prometheus-community/prometheus -n monitoring --create-namespace -f prometheus_values.yaml --version 19.0.0 This will deploy Prometheus in your Kubernetes cluster using the specified configuration in values.yaml file.","keywords":""},{"title":"Workstation","type":0,"sectionRef":"#","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation","content":"","keywords":""},{"title":"Module Purpose​","type":1,"pageTitle":"Workstation","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation#module-purpose","content":"The purpose of this module is to create the necessary infrastructure for developers, starting from firewall configuration, VPC setup, subnet configuration, and provisioning instances. It also provides the flexibility to easily add new instances for new developers or modify existing instances. "},{"title":"Adding new developer​","type":1,"pageTitle":"Workstation","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation#adding-new-developer","content":""},{"title":"1. Navigate to the Workstation Module​","type":1,"pageTitle":"Workstation","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation#1-navigate-to-the-workstation-module","content":"cd infrastructure/modules/workstation  "},{"title":"2. Modify the main.tf File​","type":1,"pageTitle":"Workstation","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation#2-modify-the-maintf-file","content":"Locals section : locals { // to add new workstation just add a new list with it's name, machine_type, your prefered os and zone workstations = { &quot;workstation1&quot; = { machine_type = &quot;e2-medium&quot;, zone = &quot;europe-west9-a&quot;, tag = [&quot;ping&quot;, &quot;ssh&quot;,&quot;metrics&quot;], image = &quot;debian-cloud/debian-11&quot;, bucket_name = &quot;uniquename&quot; }, &quot;workstation2&quot; = { machine_type = &quot;e2-micro&quot;, zone = &quot;europe-west9-a&quot;, tag = [&quot;ping&quot;, &quot;ssh&quot;,&quot;metrics&quot;], image = &quot;debian-cloud/debian-11&quot;, bucket_name = &quot;uniquename&quot; }, &quot;workstation3&quot; = { machine_type = &quot;e2-micro&quot;, zone = &quot;europe-west9-a&quot;, tag = [&quot;ping&quot;, &quot;ssh&quot;], image = &quot;debian-cloud/debian-11&quot;, bucket_name = &quot;uniquename&quot; } } }  Add a new entry for the new developer's workstation in the workstations map. Here's an example of how it should look:  "},{"title":"3. Save the main.tf file.​","type":1,"pageTitle":"Workstation","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation#3-save-the-maintf-file","content":""},{"title":"4. Apply the changes and type in the following command:​","type":1,"pageTitle":"Workstation","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation#4-apply-the-changes-and-type-in-the-following-command","content":"$ terrafrom apply  This will provision a new VM for the new developer with the specified settings. "},{"title":"Conclusion​","type":1,"pageTitle":"Workstation","url":"/docs/Infrastructure as a Code/Terraform Modules/Workstation#conclusion","content":"That's it! You should now have a new VM for the new developer ready to use. If you have any questions or run into any issues, feel free to reach out to me for assistance. "},{"title":"CentralizedSecret","type":0,"sectionRef":"#","url":"/docs/Secrets/CentralizedSecret","content":"","keywords":""},{"title":"Importance of Centralized Credentials Management with Vault by HashiCorp​","type":1,"pageTitle":"CentralizedSecret","url":"/docs/Secrets/CentralizedSecret#importance-of-centralized-credentials-management-with-vault-by-hashicorp","content":"In modern application development and infrastructure management, securely managing credentials and secrets is of paramount importance. Centralized credentials management provides several benefits, including enhanced security, improved operational efficiency, and simplified auditing and compliance. Vault by HashiCorp is a powerful tool that addresses these needs effectively. Certainly! Here's the response in markdown format: Enhanced Security: Encryption and strong cryptographic measures protect sensitive credentials.Access controls and policies ensure authorized access.Mitigates the risk of unauthorized access, data breaches, and insider threats. Improved Operational Efficiency: Centralized vault eliminates scattered credentials across systems.Single source of truth for secrets.Easy rotation, revocation, and centralized management of credentials.Seamless automation through APIs and integrations. Simplified Auditing and Compliance: Detailed audit trail of all credential access and usage.Compliance with regulations and investigation support.Policy-based access control for granular permissions management.Alignment with least privilege principles and regulatory requirements. By leveraging centralized credentials management with Vault by HashiCorp, organizations can achieve enhanced security, improved operational efficiency, and simplified auditing and compliance. "},{"title":"Exposing Metrics for Developer VMs","type":0,"sectionRef":"#","url":"/docs/Monitoring/ExposeMetrics","content":"","keywords":""},{"title":"Navigating to the Script Folder​","type":1,"pageTitle":"Exposing Metrics for Developer VMs","url":"/docs/Monitoring/ExposeMetrics#navigating-to-the-script-folder","content":"First, navigate to the folder where the script is located. Run the following command: cd scripts/metrics  "},{"title":"Running the Script​","type":1,"pageTitle":"Exposing Metrics for Developer VMs","url":"/docs/Monitoring/ExposeMetrics#running-the-script","content":"The script assumes that the instances are named as workstation1, workstation2, and so on. If you have more than three instances, you will need to modify the script accordingly. Update the for loop to match the number of instances you have. #!/bin/bash for i in {1..3} do gcloud compute scp install.sh workstation$i:. --zone=europe-west9-a gcloud compute scp node_exporter.service workstation$i:. --zone=europe-west9-a gcloud compute ssh workstation$i --command='sudo bash ./install.sh' --zone=europe-west9-a echo &quot;----------Hooray! Metrics are now exposed for workstation$i----------&quot; done  The script performs the following actions: Copies the install.sh script and node_exporter.service file to each workstation VM using the gcloud compute scp command.Connects to each workstation VM using gcloud compute ssh.Runs the install.sh script on each VM to install Node Exporter.Displays a success message indicating that metrics are now exposed for the respective workstation. Make sure you have the necessary permissions to execute the script and modify the zone according to your VMs' configuration. "},{"title":"Conclusion​","type":1,"pageTitle":"Exposing Metrics for Developer VMs","url":"/docs/Monitoring/ExposeMetrics#conclusion","content":"Congratulations! You have successfully set up the script to expose metrics for your developer VMs using Node Exporter. Now you can monitor and gather metrics from each workstation. If you encounter any issues or have any questions, please don't hesitate to reach out for assistance. We are here to help you! "},{"title":"Overview","type":0,"sectionRef":"#","url":"/docs/Monitoring/Overview","content":"","keywords":""},{"title":"Monitoring with Prometheus and Grafana​","type":1,"pageTitle":"Overview","url":"/docs/Monitoring/Overview#monitoring-with-prometheus-and-grafana","content":"Monitoring and observability are critical aspects of our development environment. Prometheus, a powerful monitoring and alerting tool, collects and analyzes metrics from our infrastructure components. With Prometheus, we can gain real-time insights into resource utilization, and system health. Grafana, a feature-rich data visualization and dashboarding tool, integrates with Prometheus to provide rich and customizable dashboards for monitoring our infrastructure. Grafana enables us to create visual representations of metrics, set up alerts, and gain deep insights into the performance and behavior of our development environment. "},{"title":"Installation of Grafana","type":0,"sectionRef":"#","url":"/docs/Monitoring/Installation of Grafana","content":"","keywords":""},{"title":"To deploy Grafana using the Helm Chart, follow these steps:​","type":1,"pageTitle":"Installation of Grafana","url":"/docs/Monitoring/Installation of Grafana#to-deploy-grafana-using-the-helm-chart-follow-these-steps","content":"Navigate to the Grafana helm chart directory:  $ cd helm_charts/grafana_chart  Add the Grafana Helm repository:  $ helm repo add grafana  Install Grafana using the Helm Chart. We provided a customized grafana_values.yaml file for our specific needs, but you can modify it according to your preferences.  helm install grafana grafana/grafana -n monitoring --create-namespace -f grafana_values.yaml --version 6.50.5  After the installation is complete, you can access the Grafana dashboard using the IP address or hostname of the Kubernetes cluster along with the port number. I set it, to Grafana service IP. "},{"title":"Integrate Vault with helm","type":0,"sectionRef":"#","url":"/docs/Secrets/Integrate Vault with helm","content":"Integrate Vault with helm","keywords":""},{"title":"This is my video script","type":0,"sectionRef":"#","url":"/docs/script/","content":"","keywords":""},{"title":"DEMO​","type":1,"pageTitle":"This is my video script","url":"/docs/script/#demo","content":"in the demo we will show the end result showing how you can use vscode to access your dedicated virtual machine access the gke namesapce access awx via keycloakaccess grafana via keycloakand show the dashboardstart serverspec pipelinetrigger awx pipelineaccess veeam backup interfaceaccess kasten backup interface and show to restore the namespace "},{"title":"Step 1 Launch Jenkins​","type":1,"pageTitle":"This is my video script","url":"/docs/script/#step-1-launch-jenkins","content":""},{"title":"1.​","type":1,"pageTitle":"This is my video script","url":"/docs/script/#1","content":""},{"title":"Integrate Vault with Jenkins","type":0,"sectionRef":"#","url":"/docs/Secrets/Integrate Vault with Jenkins","content":"Integrate Vault with Jenkins","keywords":""},{"title":"Installation & Configuration of Keycloak","type":0,"sectionRef":"#","url":"/docs/Single Sign-On with Keycloak/Installation & Configuration of Keycloak","content":"","keywords":""},{"title":"1. Navigate to the Keycloak Helm Chart directory in your Git repo:​","type":1,"pageTitle":"Installation & Configuration of Keycloak","url":"/docs/Single Sign-On with Keycloak/Installation & Configuration of Keycloak#1-navigate-to-the-keycloak-helm-chart-directory-in-your-git-repo","content":"cd helm_charts/keycloak_chart  "},{"title":"2. Add the Codecentric Helm repo:​","type":1,"pageTitle":"Installation & Configuration of Keycloak","url":"/docs/Single Sign-On with Keycloak/Installation & Configuration of Keycloak#2-add-the-codecentric-helm-repo","content":"helm repo add codecentric  "},{"title":"3. Install Keycloak using the Helm Chart:​","type":1,"pageTitle":"Installation & Configuration of Keycloak","url":"/docs/Single Sign-On with Keycloak/Installation & Configuration of Keycloak#3-install-keycloak-using-the-helm-chart","content":"I have provided chart values that are customized for our needs, but you can make changes to suit your specific requirements. Use the following command to deploy Keycloak: helm install keycloak codecentric/keycloak -f keycloak_values.yaml  That's it! Your Keycloak instance should now be up and running, you can access it with the Keycloak Service IP. "},{"title":"Install Vault","type":0,"sectionRef":"#","url":"/docs/Secrets/Install Vault","content":"","keywords":""},{"title":"Install the Vault Helm chart​","type":1,"pageTitle":"Install Vault","url":"/docs/Secrets/Install Vault#install-the-vault-helm-chart","content":"The recommended way to run Vault on Kubernetes is via the Helm chart. Go to the helm values folder in /helm_charts/vault_chart Add the HashiCorp Helm repository.  helm repo add hashicorp https://helm.releases.hashicorp.com  Update all the repositories to ensure helm is aware of the latest versions. helm repo update  Search for all the Vault Helm chart versions and choose a version.  helm search repo vault --versions  Install the version you chose of the Vault Helm chart in HA mode with integrated storage.  helm install vault hashicorp/vault \\ --set='server.ha.enabled=true' \\ --set='server.ha.raft.enabled=true' \\ -f vault_values.yaml \\ --version 0.24.0 \\ -n secrets --create-namespace  this the offical documentation on installing vault link "},{"title":"Installing the Vault Helm Chart on Kubernetes​","type":1,"pageTitle":"Install Vault","url":"/docs/Secrets/Install Vault#installing-the-vault-helm-chart-on-kubernetes","content":"To run Vault on Kubernetes, it is recommended to use the Helm chart provided by HashiCorp. The following steps outline the process of installing Vault on Kubernetes using the Helm chart: "},{"title":"Step 1: Add HashiCorp Helm Repository​","type":1,"pageTitle":"Install Vault","url":"/docs/Secrets/Install Vault#step-1-add-hashicorp-helm-repository","content":"Add the HashiCorp Helm repository to your local Helm installation by executing the following command: helm repo add hashicorp https://helm.releases.hashicorp.com  "},{"title":"Step 2: Update Helm Repositories​","type":1,"pageTitle":"Install Vault","url":"/docs/Secrets/Install Vault#step-2-update-helm-repositories","content":"Update all the repositories to ensure that Helm is aware of the latest available versions of the charts: helm repo update  "},{"title":"Step 3: Choose a Vault Helm Chart Version​","type":1,"pageTitle":"Install Vault","url":"/docs/Secrets/Install Vault#step-3-choose-a-vault-helm-chart-version","content":"Search for all available versions of the Vault Helm chart and choose the version that suits your requirements. Use the following command to search for available versions: helm search repo vault --versions  "},{"title":"Step 4: Install the Vault Helm Chart​","type":1,"pageTitle":"Install Vault","url":"/docs/Secrets/Install Vault#step-4-install-the-vault-helm-chart","content":"Install the chosen version of the Vault Helm chart in High Availability (HA) mode with integrated storage. You can use the provided vault_values.yaml file located helm_chart/vault_chart to customize the chart's configuration. Execute the following command to install the Vault Helm chart: helm install vault hashicorp/vault \\ --set='server.ha.enabled=true' \\ --set='server.ha.raft.enabled=true' \\ -f vault_values.yaml \\ --version 0.24.0 \\ -n secrets --create-namespace  "},{"title":"Additional Resources​","type":1,"pageTitle":"Install Vault","url":"/docs/Secrets/Install Vault#additional-resources","content":"For more detailed instructions and information on installing Vault on Kubernetes, you can refer to the official documentation: Kubernetes-Google Cloud GKE Tutorial. By following these steps, you will be able to successfully install and configure Vault on your Kubernetes cluster using the Helm chart. "},{"title":"Overview","type":0,"sectionRef":"#","url":"/docs/Single Sign-On with Keycloak/Overview","content":"","keywords":""},{"title":"Single Sign-On with Keycloak​","type":1,"pageTitle":"Overview","url":"/docs/Single Sign-On with Keycloak/Overview#single-sign-on-with-keycloak","content":"Implementing a Single Sign-On (SSO) solution is essential for ensuring secure and streamlined access to our development environment. Keycloak, a flexible and open-source SSO solution, provides centralized authentication and access control. With Keycloak, we can integrate our infrastructure components, such as Grafana, AWX and more, allowing our team members to authenticate once and seamlessly access multiple services. Keycloak enhances security, simplifies user management, and offers features like role-based access control (RBAC) and multi-factor authentication (MFA). "},{"title":"Congratulations!","type":0,"sectionRef":"#","url":"/docs/tutorial-basics/congratulations","content":"","keywords":""},{"title":"What's next?​","type":1,"pageTitle":"Congratulations!","url":"/docs/tutorial-basics/congratulations#whats-next","content":"Read the official documentationModify your site configuration with docusaurus.config.jsAdd navbar and footer items with themeConfigAdd a custom Design and LayoutAdd a search barFind inspirations in the Docusaurus showcaseGet involved in the Docusaurus Community "},{"title":"Create a Blog Post","type":0,"sectionRef":"#","url":"/docs/tutorial-basics/create-a-blog-post","content":"","keywords":""},{"title":"Create your first Post​","type":1,"pageTitle":"Create a Blog Post","url":"/docs/tutorial-basics/create-a-blog-post#create-your-first-post","content":"Create a file at blog/2021-02-28-greetings.md: blog/2021-02-28-greetings.md --- slug: greetings title: Greetings! authors: - name: Joel Marcey title: Co-creator of Docusaurus 1 url: https://github.com/JoelMarcey image_url: https://github.com/JoelMarcey.png - name: Sébastien Lorber title: Docusaurus maintainer url: https://sebastienlorber.com image_url: https://github.com/slorber.png tags: [greetings] --- Congratulations, you have made your first post! Feel free to play around and edit this post as much you like.  A new blog post is now available at http://localhost:3000/blog/greetings. "},{"title":"Integration with Grafana","type":0,"sectionRef":"#","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana","content":"","keywords":""},{"title":"Integrate Keycloak with Grafana​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#integrate-keycloak-with-grafana","content":""},{"title":"1. Create a \"grafana\" Realm using Keycloak's web interface.​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#1-create-a-grafana-realm-using-keycloaks-web-interface","content":""},{"title":"2. Navigate to the location where the Keycloak Terraform file is stored:​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#2-navigate-to-the-location-where-the-keycloak-terraform-file-is-stored","content":"cd infrastructure/modules/keycloak  "},{"title":"3. Modify the default values of the variables.tf file to match the IP or domain of your Keycloak and Grafana services:​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#3-modify-the-default-values-of-the-variablestf-file-to-match-the-ip-or-domain-of-your-keycloak-and-grafana-services","content":"# ip or hostname of the keycloak server variable &quot;keycloak&quot; { type = string description = &quot;keycloak ip or hostname&quot; default = &quot;http://&lt;put here the ip or the domain of keycloak service&gt;&quot; } # grafana ip or hostname variable &quot;grafana&quot; { type = string description = &quot;grafana redirect uri ip or hostname&quot; default = &quot;http://&lt;put here the ip or the domain of grafana service&gt;/login/generic_oauth&quot; }  "},{"title":"4. Run the following command to create the configuration and users:​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#4-run-the-following-command-to-create-the-configuration-and-users","content":"terraform init terraform apply --auto-aprouve  "},{"title":"5. Navigate to your newly created Realm in Keycloak and add a password for your USER and ADMIN.​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#5-navigate-to-your-newly-created-realm-in-keycloak-and-add-a-password-for-your-user-and-admin","content":""},{"title":"6. In Grafana_values.yaml, update the IP address in the grafana.ini section.​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#6-in-grafana_valuesyaml-update-the-ip-address-in-the-grafanaini-section","content":"# go to the line 692 grafana.ini: auth.generic_oauth: enabled: true name: Keycloak allow_sign_up: true scopes: profile,email,groups auth_url: &lt;Keycloak service ip or domain&gt;/auth/realms/grafana/protocol/openid-connect/auth token_url: &lt;Keycloak service ip or domain&gt;/auth/realms/grafana/protocol/openid-connect/token api_url: &lt;Keycloak service ip or domain&gt;/auth/realms/grafana/protocol/openid-connect/userinfo client_id: grafana client_secret: grafana-client-secret role_attribute_path: contains(groups[*], 'grafana-admin') &amp;&amp; 'Admin' || contains(groups[*], 'grafana-dev') &amp;&amp; 'Editor' || 'Viewer' server: # this is for grafana url root_url: &lt;grafana ip or domain name&gt;  "},{"title":"7. Navigate back to Grafana Chart and Upgrade the changes you made​","type":1,"pageTitle":"Integration with Grafana","url":"/docs/Single Sign-On with Keycloak/Integration with Grafana#7-navigate-back-to-grafana-chart-and-upgrade-the-changes-you-made","content":"helm upgrade grafana grafana/grafana -f grafana_values.yaml  "},{"title":"How to Integrate Keycloak with AWX","type":0,"sectionRef":"#","url":"/docs/Single Sign-On with Keycloak/Integration with AWX","content":"","keywords":""},{"title":"1. Navigate to setttings on AWX -> Miscellaneous System settings​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#1-navigate-to-setttings-on-awx---miscellaneous-system-settings","content":""},{"title":"2. Edit Base URL of the service to your base URL or IP​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#2-edit-base-url-of-the-service-to-your-base-url-or-ip","content":""},{"title":"3. Go back to Settings, then SAML settings and replace the fields as shown below:​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#3-go-back-to-settings-then-saml-settings-and-replace-the-fields-as-shown-below","content":""},{"title":"SAML Service Provider Entity ID​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#saml-service-provider-entity-id","content":"https://keycloakdomainname  "},{"title":"SAML Service Provider Public Certificate​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#saml-service-provider-public-certificate","content":""},{"title":"SAML Service Provider Private Key​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#saml-service-provider-private-key","content":""},{"title":"Generate a certificate and Public key by typing in :​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#generate-a-certificate-and-public-key-by-typing-in-","content":"openssl req -new -x509 -days 3650 -nodes -out saml.crt -keyout saml.key  SAML Service Provider Organization Info: { &quot;en-US&quot;: { &quot;url&quot;: &quot;http://keycloakserviceip&quot;, &quot;name&quot;: &quot;keycloak&quot;, &quot;displayname&quot;: &quot;keycloak&quot; } }   Specify SAML Service Provider Technical Contact: { &quot;emailAddress&quot;: &quot;chamseddine.abderrahim@gmail.com&quot;, &quot;givenName&quot;: &quot;chamseddine&quot; }   Specify Service Provider Support Contact: { &quot;emailAddress&quot;: &quot;chamseddine.abderrahim@gmail.com&quot;, &quot;givenName&quot;: &quot;chamseddine&quot; }   Specify SAML Enabled Identity Provider: { &quot;keycloak&quot;: { &quot;x509cert&quot;: &quot;certificatewithoutbreakinglines&quot;, &quot;attr_first_name&quot;: &quot;first_name&quot;, &quot;attr_email&quot;: &quot;email&quot;, &quot;url&quot;: &quot;http://keycloakserviceip/auth/realms/tower/protocol/saml&quot;, &quot;attr_user_permanent_id&quot;: &quot;name_id&quot;, &quot;entity_id&quot;: &quot;http://keycloakserviceip/auth/realms/tower&quot;, &quot;attr_groups&quot;: &quot;groups&quot;, &quot;attr_last_name&quot;: &quot;last_name&quot;, &quot;attr_username&quot;: &quot;username&quot; } }   Specify SAML Organization Map: { &quot;Default&quot;: { &quot;users&quot;: true }, &quot;Systems Engineering&quot;: { &quot;remove_users&quot;: false, &quot;remove_admins&quot;: false, &quot;users&quot;: true, &quot;admins&quot;: [ &quot;chamseddine.abderrahim@gmail.com&quot; ] } }   "},{"title":"Verify your Configuration by typing this command and upload it to keycloak when creating your client:​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#verify-your-configuration-by-typing-this-command-and-upload-it-to-keycloak-when-creating-your-client","content":"curl -k -L http://AwxServiceIP/sso/metadata/saml/ &gt; awx-keycloak.xml  "},{"title":"Keycloak Side​","type":1,"pageTitle":"How to Integrate Keycloak with AWX","url":"/docs/Single Sign-On with Keycloak/Integration with AWX#keycloak-side","content":"Create Your REALM named: tower Import the &quot;awx-keycloak.xml&quot; to your REALM   Add Your certificate and Private key to your REALME   Add Mappers for the saml request nagivate to infrastructure/modules/awxsaml and type in: Important Change the variable values inside variables.tf file to match your service URL etc.... terraform init terraform apply  Verify the SSO is working  "},{"title":"Configure Vault Cluster","type":0,"sectionRef":"#","url":"/docs/Secrets/Configure Vault","content":"","keywords":""},{"title":"Step 1: Initialize and unseal one Vault pod​","type":1,"pageTitle":"Configure Vault Cluster","url":"/docs/Secrets/Configure Vault#step-1-initialize-and-unseal-one-vault-pod","content":"To start, Vault needs to be initialized and unsealed. Follow these steps: Initialize Vault with one key share and one key threshold: kubectl exec -n secrets vault-0 -- vault operator init -key-shares=1 -key-threshold=1 -format=json &gt; cluster-keys.json  Display the unseal key found in cluster-keys.json: cat cluster-keys.json | jq -r &quot;.unseal_keys_b64[]&quot;  Create a variable named VAULT_UNSEAL_KEY to capture the Vault unseal key: VAULT_UNSEAL_KEY=$(cat cluster-keys.json | jq -r &quot;.unseal_keys_b64[]&quot;)  Unseal Vault running on the vault-0 pod: kubectl exec -n secrets vault-0 -- vault operator unseal $VAULT_UNSEAL_KEY  "},{"title":"Step 2: Join the other Vaults to the Vault cluster​","type":1,"pageTitle":"Configure Vault Cluster","url":"/docs/Secrets/Configure Vault#step-2-join-the-other-vaults-to-the-vault-cluster","content":"To create a Vault HA cluster, you need to join the other Vaults to the cluster. Here's how: Display the root token found in cluster-keys.json: cat cluster-keys.json | jq -r &quot;.root_token&quot;  Create a variable named CLUSTER_ROOT_TOKEN to capture the Vault root token: CLUSTER_ROOT_TOKEN=$(cat cluster-keys.json | jq -r &quot;.root_token&quot;)  Login with the root token on the vault-0 pod: kubectl exec -n secrets vault-0 -- vault login $CLUSTER_ROOT_TOKEN  List all the nodes within the Vault cluster for the vault-0 pod: kubectl exec -n secrets vault-0 -- vault operator raft list-peers   Join the Vault server on vault-1 to the Vault cluster: kubectl exec -n secrets vault-1 -- vault operator raft join http://vault-0.vault-internal:8200  Unseal the Vault server on vault-1 with the unseal key: kubectl exec -n secrets vault-1 -- vault operator unseal $VAULT_UNSEAL_KEY   Join the Vault server on vault-2 to the Vault cluster: kubectl exec -n secrets vault-2 -- vault operator raft join http://vault-0.vault-internal:8200  Unseal the Vault server on vault-2 with the unseal key: kubectl exec -n secrets vault-2 -- vault operator unseal $VAULT_UNSEAL_KEY   List all the nodes within the Vault cluster for the vault-0 pod: kubectl exec -n secrets vault-0 -- vault operator raft list-peers  "},{"title":"Verify Cluster Status​","type":1,"pageTitle":"Configure Vault Cluster","url":"/docs/Secrets/Configure Vault#verify-cluster-status","content":"To ensure the Vault cluster is properly set up, follow these steps: Get all the pods within the default namespace: kubectl get pods -n secrets  Check that the vault-0, vault-1, and vault-2 pods are running and ready (1/1).  "},{"title":"Deploy your site","type":0,"sectionRef":"#","url":"/docs/tutorial-basics/deploy-your-site","content":"","keywords":""},{"title":"Build your site​","type":1,"pageTitle":"Deploy your site","url":"/docs/tutorial-basics/deploy-your-site#build-your-site","content":"Build your site for production: npm run build  The static files are generated in the build folder. "},{"title":"Deploy your site​","type":1,"pageTitle":"Deploy your site","url":"/docs/tutorial-basics/deploy-your-site#deploy-your-site-1","content":"Test your production build locally: npm run serve  The build folder is now served at http://localhost:3000/. You can now deploy the build folder almost anywhere easily, for free or very small cost (read the Deployment Guide). "},{"title":"Create a Page","type":0,"sectionRef":"#","url":"/docs/tutorial-basics/create-a-page","content":"","keywords":""},{"title":"Create your first React Page​","type":1,"pageTitle":"Create a Page","url":"/docs/tutorial-basics/create-a-page#create-your-first-react-page","content":"Create a file at src/pages/my-react-page.js: src/pages/my-react-page.js import React from 'react'; import Layout from '@theme/Layout'; export default function MyReactPage() { return ( &lt;Layout&gt; &lt;h1&gt;My React page&lt;/h1&gt; &lt;p&gt;This is a React page&lt;/p&gt; &lt;/Layout&gt; ); }  A new page is now available at http://localhost:3000/my-react-page. "},{"title":"Create your first Markdown Page​","type":1,"pageTitle":"Create a Page","url":"/docs/tutorial-basics/create-a-page#create-your-first-markdown-page","content":"Create a file at src/pages/my-markdown-page.md: src/pages/my-markdown-page.md # My Markdown page This is a Markdown page  A new page is now available at http://localhost:3000/my-markdown-page. "},{"title":"Manage Docs Versions","type":0,"sectionRef":"#","url":"/docs/tutorial-extras/manage-docs-versions","content":"","keywords":""},{"title":"Create a docs version​","type":1,"pageTitle":"Manage Docs Versions","url":"/docs/tutorial-extras/manage-docs-versions#create-a-docs-version","content":"Release a version 1.0 of your project: npm run docusaurus docs:version 1.0  The docs folder is copied into versioned_docs/version-1.0 and versions.json is created. Your docs now have 2 versions: 1.0 at http://localhost:3000/docs/ for the version 1.0 docscurrent at http://localhost:3000/docs/next/ for the upcoming, unreleased docs "},{"title":"Add a Version Dropdown​","type":1,"pageTitle":"Manage Docs Versions","url":"/docs/tutorial-extras/manage-docs-versions#add-a-version-dropdown","content":"To navigate seamlessly across versions, add a version dropdown. Modify the docusaurus.config.js file: docusaurus.config.js module.exports = { themeConfig: { navbar: { items: [ { type: 'docsVersionDropdown', }, ], }, }, };  The docs version dropdown appears in your navbar:  "},{"title":"Update an existing version​","type":1,"pageTitle":"Manage Docs Versions","url":"/docs/tutorial-extras/manage-docs-versions#update-an-existing-version","content":"It is possible to edit versioned docs in their respective folder: versioned_docs/version-1.0/hello.md updates http://localhost:3000/docs/hellodocs/hello.md updates http://localhost:3000/docs/next/hello "},{"title":"Create a Document","type":0,"sectionRef":"#","url":"/docs/tutorial-basics/create-a-document","content":"","keywords":""},{"title":"Create your first Doc​","type":1,"pageTitle":"Create a Document","url":"/docs/tutorial-basics/create-a-document#create-your-first-doc","content":"Create a Markdown file at docs/hello.md: docs/hello.md # Hello This is my **first Docusaurus document**!  A new document is now available at http://localhost:3000/docs/hello. "},{"title":"Configure the Sidebar​","type":1,"pageTitle":"Create a Document","url":"/docs/tutorial-basics/create-a-document#configure-the-sidebar","content":"Docusaurus automatically creates a sidebar from the docs folder. Add metadata to customize the sidebar label and position: docs/hello.md --- sidebar_label: 'Hi!' sidebar_position: 3 --- # Hello This is my **first Docusaurus document**!  It is also possible to create your sidebar explicitly in sidebars.js: sidebars.js module.exports = { tutorialSidebar: [ 'intro', 'hello', { type: 'category', label: 'Tutorial', items: ['tutorial-basics/create-a-document'], }, ], };  "},{"title":"Translate your site","type":0,"sectionRef":"#","url":"/docs/tutorial-extras/translate-your-site","content":"","keywords":""},{"title":"Configure i18n​","type":1,"pageTitle":"Translate your site","url":"/docs/tutorial-extras/translate-your-site#configure-i18n","content":"Modify docusaurus.config.js to add support for the fr locale: docusaurus.config.js module.exports = { i18n: { defaultLocale: 'en', locales: ['en', 'fr'], }, };  "},{"title":"Translate a doc​","type":1,"pageTitle":"Translate your site","url":"/docs/tutorial-extras/translate-your-site#translate-a-doc","content":"Copy the docs/intro.md file to the i18n/fr folder: mkdir -p i18n/fr/docusaurus-plugin-content-docs/current/ cp docs/intro.md i18n/fr/docusaurus-plugin-content-docs/current/intro.md  Translate i18n/fr/docusaurus-plugin-content-docs/current/intro.md in French. "},{"title":"Start your localized site​","type":1,"pageTitle":"Translate your site","url":"/docs/tutorial-extras/translate-your-site#start-your-localized-site","content":"Start your site on the French locale: npm run start -- --locale fr  Your localized site is accessible at http://localhost:3000/fr/ and the Getting Started page is translated. caution In development, you can only use one locale at a same time. "},{"title":"Add a Locale Dropdown​","type":1,"pageTitle":"Translate your site","url":"/docs/tutorial-extras/translate-your-site#add-a-locale-dropdown","content":"To navigate seamlessly across languages, add a locale dropdown. Modify the docusaurus.config.js file: docusaurus.config.js module.exports = { themeConfig: { navbar: { items: [ { type: 'localeDropdown', }, ], }, }, };  The locale dropdown now appears in your navbar:  "},{"title":"Build your localized site​","type":1,"pageTitle":"Translate your site","url":"/docs/tutorial-extras/translate-your-site#build-your-localized-site","content":"Build your site for a specific locale: npm run build -- --locale fr  Or build your site to include all the locales at once: npm run build  "},{"title":"Markdown Features","type":0,"sectionRef":"#","url":"/docs/tutorial-basics/markdown-features","content":"","keywords":""},{"title":"Front Matter​","type":1,"pageTitle":"Markdown Features","url":"/docs/tutorial-basics/markdown-features#front-matter","content":"Markdown documents have metadata at the top called Front Matter: my-doc.md --- id: my-doc-id title: My document title description: My document description slug: /my-custom-url --- ## Markdown heading Markdown text with [links](./hello.md)  "},{"title":"Links​","type":1,"pageTitle":"Markdown Features","url":"/docs/tutorial-basics/markdown-features#links","content":"Regular Markdown links are supported, using url paths or relative file paths. Let's see how to [Create a page](/create-a-page).  Let's see how to [Create a page](./create-a-page.md).  Result: Let's see how to Create a page. "},{"title":"Images​","type":1,"pageTitle":"Markdown Features","url":"/docs/tutorial-basics/markdown-features#images","content":"Regular Markdown images are supported. You can use absolute paths to reference images in the static directory (static/img/docusaurus.png): ![Docusaurus logo](/img/docusaurus.png)   You can reference images relative to the current file as well. This is particularly useful to colocate images close to the Markdown files using them: ![Docusaurus logo](./img/docusaurus.png)  "},{"title":"Code Blocks​","type":1,"pageTitle":"Markdown Features","url":"/docs/tutorial-basics/markdown-features#code-blocks","content":"Markdown code blocks are supported with Syntax highlighting. ```jsx title=&quot;src/components/HelloDocusaurus.js&quot; function HelloDocusaurus() { return ( &lt;h1&gt;Hello, Docusaurus!&lt;/h1&gt; ) } ```  src/components/HelloDocusaurus.js function HelloDocusaurus() { return &lt;h1&gt;Hello, Docusaurus!&lt;/h1&gt;; }  "},{"title":"Admonitions​","type":1,"pageTitle":"Markdown Features","url":"/docs/tutorial-basics/markdown-features#admonitions","content":"Docusaurus has a special syntax to create admonitions and callouts: :::tip My tip Use this awesome feature option ::: :::danger Take care This action is dangerous :::  My tip Use this awesome feature option Take care This action is dangerous "},{"title":"MDX and React Components​","type":1,"pageTitle":"Markdown Features","url":"/docs/tutorial-basics/markdown-features#mdx-and-react-components","content":"MDX can make your documentation more interactive and allows using any React components inside Markdown: export const Highlight = ({children, color}) =&gt; ( &lt;span style={{ backgroundColor: color, borderRadius: '20px', color: '#fff', padding: '10px', cursor: 'pointer', }} onClick={() =&gt; { alert(`You clicked the color ${color} with label ${children}`) }}&gt; {children} &lt;/span&gt; ); This is &lt;Highlight color=&quot;#25c2a0&quot;&gt;Docusaurus green&lt;/Highlight&gt; ! This is &lt;Highlight color=&quot;#1877F2&quot;&gt;Facebook blue&lt;/Highlight&gt; !  This is Docusaurus green ! This is Facebook blue ! "}]